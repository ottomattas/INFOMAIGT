Please keep the questions in your answer, as I don't remember the questions by heart. ;)

-----------------------
Question 1: What does the term "model-free" from the lecture refer to?
- A reinforcement learning method which does not include the use of a reward function or giving probability to transitions, both of which are commonly connected to Markovian approaches.
-----------------------
Question 2: What does the term bootstrapping refer to?
- A resampling method for the data corpus, where use of replacement data points can relatively easily help with achieving multiple goals, including greater accuracy in predictions over periods of time.
-----------------------
Question 3: What does it mean that TD can learn "online"?
- TD-learning incorporates continuously updating its model to give improved predictions for future outcomes.
-----------------------
Question 4: Why has Monte Carlo learning a higher variance than TD-learning?
- As TD-learning generally uses less sampled variables, TD also comes with proportionally less variance. Monte Carlo on the other hand relies on complete value trajectories which can bring very different values.
-----------------------
Question 5: Why is TD-learning said to have bias and what is meant by this?
- TD-learning consists of estimating state-values and continuously updating those values. The actual values are not checked and might be different.
-----------------------
Question 6: Why is TD-learning more sensitive to initial values?
- As for TD-learning, the success of a particular algorithm really depends on initial values. The same algorithm will perform differently from different initial values due to bootstrapping.
-----------------------
Question 7: What is the difference of the expectation and the average?
- The expectation (expected return) will describe the prediction made. The average will describe the state-values as they are learned.
-----------------------
Question 8: Once, we fix a policy a Markov decision process becomes?

Correction:
What does an MDP become once we fix a policy?
- Negligible.
-----------------------
Question 9: What does the law of large numbers refer to?
- A theorem in probability theory which states that upon sample size growth, the mean gets closer to the average.
-----------------------
Question 10: What is the role of alpha in lecture 6?
- To simplify the algorithm for flexible contexts where it's not necessary to consider every possible step and having a fixed number of steps suffices.